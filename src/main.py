# -*- coding: utf-8 -*-
"""
Created on Tue Jul 13 11:09:51 2021

@author: Gustavo

"""
#!/usr/bin/python
import sys, getopt
import subprocess 
import time
from datetime import timedelta
import re
import nltk
from bs4 import BeautifulSoup
from nltk.corpus import wordnet
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.firefox.options import Options as FirefoxOptions
import io
import string
start_time = time.monotonic()

url = ''
settings = ''
wordlist = './docs/directory-list-2.3-small.txt' 

def main(argv):
   
   try:
      opts, args = getopt.getopt(argv,"hu:o",["url=","set="])
   except getopt.GetoptError:
      print('main.py -u <url> -s <settings>')
      sys.exit(2)
   for opt, arg in opts:
      if opt == '-h':
         print('main.py -u <url> -s <settings>')
         sys.exit()
      elif opt in ("-u", "--url"):
         url = arg
      elif opt in ("-o", "--set"):
         settings = arg
   print('Target URL is ', url)
   
   #The settings are currently hardcoded eg. basic auth
   #print('Settings: ', settings)
   
   subprocess.call(["python3", "./dirsearch/dirsearch.py", "-u" + url,
                    "--auth=standard_user:secret_sauce", "--auth-type=basic",
                    "-w" + wordlist, '--format=json', '-f',
                    '--follow-redirects'])
   
   readJson()
   runPipeline(url)
   reRun(url)
   
   print(url,  file=open('./url.txt', 'w'))
   
   
def readJson():
    
    import json
    import csv
    import io
    
    with open('report.csv', 'r') as infile:
      # read the file as a dictionary for each row ({header : value})
      reader = csv.DictReader(infile)
      data = {}
      for row in reader:
        for header, value in row.items():
          try:
            data[header].append(value)
          except KeyError:
            data[header] = [value]        
    
    # extract data
    filename = data['filename'][0]
    netloc = data['netloc'][0]
    
    with io.open('./dirsearch/reports/' + netloc + '/' + filename,
                 encoding="utf-8") as f:
        
         data = json.load(f)
         path = data['results']
         print(path[0])    
        

wordlistList = []


def runPipeline(url):
    
    #Fetch current time
    now = datetime.now().replace(microsecond=0)
    timestamp = int(datetime.timestamp(now))
    
    
    # start web browser headlessly
    options = FirefoxOptions()
    options.add_argument("--headless")
    browser=webdriver.Firefox(options=options)
    
    
    # get source code
    name = 'html'
    browser.get(url)
    html = browser.page_source
    time.sleep(2)
    
    #Create html file
    with io.open(name + '.html', 'w', encoding="utf-8") as f:
                        
        f.write(html)
    
    
    nltk.download('wordnet')
    
    #Load wordlist 1 (succesful paths)
    file = open('words.txt', 'r')
    wordlist1 = list(file.read().split())
    
    
    # remove punctuation from each word
    table = str.maketrans('', '', string.punctuation)
    wordlist1 = [w.translate(table) for w in wordlist1]
    
    #get rid of extension
    wordlist1 = [w.replace("php", "") for w in wordlist1]
    wordlist1 = [w.replace("aspx", "") for w in wordlist1]
    wordlist1 = [w.replace("jsp", "") for w in wordlist1]
    wordlist1 = [w.replace("html", "") for w in wordlist1]
    wordlist1 = [w.replace("js", "") for w in wordlist1]
    
    #Load wordlist 2 (dirbuster 'medium' wordlist)
    file = open('./docs/directory-list-2.3-medium.txt', 'r')
    wordlist2 = list(file.read().split())
    
    #Create wordlist from HTML file
    nltk.download('punkt')
    
    #Load HTML
    url2 = name + '.html'   
    html = open(url2,'r', encoding="utf-8").read()
    
    #Get text from source code    
    wordlist3 = BeautifulSoup(html, "html.parser").get_text()
    
    
    print(re.sub("\s{2,}", " ", wordlist3))
    
    #delete /n from text and print to file for
    print(re.sub("\s{2,}", " ", wordlist3),  file=open('htmltext.txt', 'w'))
    print('++One-sentence summary:',  file=open('htmltext.txt', 'a'))
    
    
    wordlist3 = list(wordlist3.split())
    
    #combine lists
    w = wordlist2 + wordlist3
    
    #Delete duplicates 
    w = list(dict.fromkeys(w))
    
    #Convert w to Text format 
    w = nltk.Text(w)
    
    #remove rest of duplicates from list 
    w = list(set(w))
    
       
    list1 = wordlist1
    list2 = w
    
    list0 = []
    sim = []
    
    os.makedirs("clusters" + str(timestamp), exist_ok=True)    
    
    #get similarity index
    for word1 in list1:
        for word2 in list2:
            wordFromList1 = wordnet.synsets(word1)
            wordFromList2 = wordnet.synsets(word2)
            if wordFromList1 and wordFromList2: 
                s = wordFromList1[0].wup_similarity(wordFromList2[0])
                if s == None:
                    pass
                else:
                    if s > 0.7:
                        list0.append(s)
                        sim.append(word2)
                        print(word1, word2,'=', s)
                        wordlistList.append('./' + 'clusters' + str(timestamp) 
                                            + '/_' + word1 + '.txt')
    
        #Cluster for succesful word
        for i in range(len(sim)):
            print(sim[i])
               
            with open('./' + 'clusters' + str(timestamp) + '/_' + word1 + 
                      '.txt', 'w') as file_handler:
                for item in sim:
                    file_handler.write("{}\n".format(item))
                    
        sim.clear()               
                
def reRun(url):
        

    for i in range(len(wordlistList)):
        wordlistList[i] = wordlistList[i].lower()
            
    res = list(set(wordlistList))
    
    print(res)
                    
    joined_string = ",".join(res)
    print(joined_string)
    print('url=', url)
    subprocess.call(["python3", "../dirsearch/dirsearch.py", "-u" + 
                     url, "--wordlists=" + 
                   joined_string, '--format=json', '-f', '-r',  
                   "--auth=standard_user:secret_sauce", "--auth-type=basic",
                   "--follow-redirects"])

    
if __name__ == "__main__":
   main(sys.argv[1:])
 
    
subprocess.call(["python3", "cheatsheet.py"])

   
end_time = time.monotonic()
print(timedelta(seconds=end_time - start_time)) 